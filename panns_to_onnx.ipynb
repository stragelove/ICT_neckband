{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc9dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from models import Cnn14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629a8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "1.17.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0537115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c91ffca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn14(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_block1): ConvBlock(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block2): ConvBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block3): ConvBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block4): ConvBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block5): ConvBlock(\n",
       "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block6): ConvBlock(\n",
       "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT = \"./checkpoint/Cnn14_16k_mAP=0.438.pth\" # 모델의 사전학습된 가중치\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda 사용 가능여부 확인\n",
    "# print(device)\n",
    "\n",
    "model = Cnn14(\n",
    "    sample_rate=16000, # 샘플링 레이트 16k\n",
    "    window_size=512, # 윈도우 사이즈\n",
    "    hop_size=160, # 홉 사이즈\n",
    "    mel_bins=64, # mel 주파수 채널 수\n",
    "    fmin=50, # mel 주파수 최소치\n",
    "    fmax=8000, # mel 주파수 최대치\n",
    "    classes_num=527 # 분류할 클래스 숫자\n",
    ")\n",
    "checkpoint = torch.load(CHECKPOINT, map_location=device, weights_only=False) # 사전학습된 가중치 로드\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "model.eval() # 모델을 추론모드로 변경\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934caa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STFT 입력층의 패딩의 형태를 상수의 형대로 정하는 코드\n",
    "모델의 기본값은 \"reflect\" 이나\n",
    "onnx 와의 호환성을 위해 \"constant\" 변경\n",
    "'''\n",
    "model.spectrogram_extractor.stft.pad_mode = \"constant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 16000, device=device) # 모델의 입력 텐서의 예시 현재 모델은 (배치사이즈, 길이)로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdb389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Threadnull\\anaconda3\\envs\\pytorch_2.6.0\\Lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:308: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:180.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\Threadnull\\anaconda3\\envs\\pytorch_2.6.0\\Lib\\site-packages\\torch\\onnx\\utils.py:657: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:180.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\Threadnull\\anaconda3\\envs\\pytorch_2.6.0\\Lib\\site-packages\\torch\\onnx\\utils.py:1127: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:180.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "# onnx 모델 변환\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    'panns_cnn14.onnx', # 저장 경로\n",
    "    input_names=['input'], # 입력 노드 이름\n",
    "    output_names=['output'], # 출력 노드 이름\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}, # 입력과 출력의 0차원(배치사이즈)의 동적입력을 위한 설정\n",
    "    opset_version=11 # onnx의 연산자 버전\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968952c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'onnx/panns_cnn14.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 시각화\n",
    "import netron\n",
    "netron.start (\"onnx/panns_cnn14.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2.6.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

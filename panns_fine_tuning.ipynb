{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f296e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import Cnn14\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "557c094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "989ffb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./Dataset/\" # 데이터셋 경로\n",
    "CHECKPOINT = \"./checkpoint/Cnn14_16k_mAP=0.438.pth\" # 모델의 사전학습된 가중치\n",
    "SAVE_PATH = \"./result/best.pt\" # 학습완료된 모델 저장 위치\n",
    "CLASS_NAME = [\"danger\", \"fire\", \"gas\", \"non\", \"tsunami\"] # 분류할 클래스\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # torch에 전달할 디바이스 종류\n",
    "\n",
    "# 하이퍼 파라미터\n",
    "CLASS_NUM = len(CLASS_NAME) # 분류할 클래스의 개수\n",
    "SAMPLE_RATE = 16000 # 샘플링 레이트\n",
    "DURATION = 1 # 샘플의 길이\n",
    "BATCH_SIZE = 32 # 배치사이즈\n",
    "EPOCHS = 20  # 학습 에폭 수\n",
    "LEARNING_RATE = 1e-4 # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab126c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68f93dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassNameError(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"폴더이름과 클래스이름이 일치 하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "98565d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 정의\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels, sample_rate=SAMPLE_RATE, duration=DURATION):\n",
    "        self.filepaths = filepaths # 데이터 경로\n",
    "        self.labels = labels # 라벨\n",
    "        self.sample_rate = sample_rate # 샘플링 레이트\n",
    "        self.num_samples = int(sample_rate * duration) # 오디오 샘플의 길이\n",
    "\n",
    "    # 데이터셋의 길이(파일 개수) 반환\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.filepaths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        waveform, sr = torchaudio.load(filepath) # waveform의 shape(channel, length)\n",
    "\n",
    "        # 모노(1채널)로 변환\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # 원하는 샘플링 레이트가 아니면 리샘플링\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # 오디오 샘플의 길이조정\n",
    "        if waveform.shape[1] < self.num_samples: # 길이가 부족하면 0(무음)을 채워 길이를 연장\n",
    "            waveform = F.pad(waveform, (0, self.num_samples - waveform.shape[1])) # num_samples와 현재의 길이의 차 만큼 0을 패딩\n",
    "        else:\n",
    "            waveform = waveform[:, :self.num_samples] # 길이가 길면 슬라이싱\n",
    "\n",
    "        # 절댓값 정규화(-1 ~ 1)\n",
    "        waveform = waveform / (waveform.abs().max() + 1e-9)\n",
    "        '''\n",
    "        샘플의 shape를 모델에 맞추기\n",
    "        샘플은 전처리과정을 거쳐 모노화(1채널)와 \n",
    "        길이가 고정 되어 (1, 160000) 형태\n",
    "        모델은 (batch_size, data_length)형태의 입력을 받는다\n",
    "        여기서 필요한 부분은 data_length뿐 채널의 정보는 필요없다\n",
    "        그래서 채널정보를 제거하기위해 squeeze()\n",
    "        '''\n",
    "        waveform = waveform.squeeze(0)\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8403fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습함수\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() # 학습모드\n",
    "    running_loss = 0.0 # 손실\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # 배치 단위로 데이터로드\n",
    "    for waveforms, labels in tqdm(loader, desc=\"학습중\", leave=True):\n",
    "        waveforms = waveforms.to(device) # gpu로 전달\n",
    "        labels = labels.to(device).float() # BCE 손실함수에는 반드시 실수형필요\n",
    "\n",
    "        optimizer.zero_grad() # 경사값 초기화\n",
    "\n",
    "        outputs = model(waveforms)[\"clipwise_output\"] # 모델에 데이터입력\n",
    "\n",
    "        loss = criterion(outputs, labels) # 손실계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 갱신\n",
    "\n",
    "        # 배치 손실을 누적\n",
    "        running_loss += loss.item() * waveforms.size(0)\n",
    "\n",
    "        # 예측 임계값 0.5 이상을 양성 클래스라 판단하여 이진 예측 생성\n",
    "        predicts = (outputs > 0.5).int()\n",
    "        targets = labels.int()\n",
    "\n",
    "        # 모든 클래스가 일치하는 샘플 개수 카운트, 모든 클래스 다 맞아야 정답 처리\n",
    "        total_correct += (predicts == targets).all(dim=1).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total_samples # 평균손실\n",
    "    accuracy = total_correct  / total_samples # 정답 개수 / 전체 예측값 개수\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 검증함수\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval() #평가모드\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # 검증에는 기울기 계산필요없음, 즉 역전파 없음\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in tqdm(loader, desc=\"검증중\", leave=True):\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(waveforms)[\"clipwise_output\"]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * waveforms.size(0)\n",
    "\n",
    "            predicts = (outputs > 0.5).int()\n",
    "            targets = labels.int()\n",
    "\n",
    "            total_correct += (predicts == targets).all(dim=1).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = total_correct  / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d1c7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 라벨\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "# 데이터셋과 하위폴더에서 확장자가 \"wav\"인 파일의 경로와 라벨(폴더이름) 저장\n",
    "for root, _, files in os.walk(DATASET):\n",
    "    folder_name = os.path.basename(root)\n",
    "\n",
    "    # 폴더명이 클래스 리스트에 없는 경우 에러\n",
    "    if folder_name not in CLASS_NAME and folder_name != \"\":\n",
    "        raise ClassNameError\n",
    "    \n",
    "    for file in files:\n",
    "        if not file.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(root, file)\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(folder_name)\n",
    "\n",
    "# 문자열 라벨 → 정수인코딩 → 원핫인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(labels).reshape(-1, 1)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_labels = onehot_encoder.fit_transform(integer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ff12fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91abf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 8:1:1의 비율을 가진 학습, 검증, 테스트로 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    filepaths, # X\n",
    "    encoded_labels, # y\n",
    "    test_size=0.2, # train과 임시데이터셋 비율 8:2\n",
    "    stratify=labels, # 기준값을 기준으로 동일한 클래스의 비율로 나누기\n",
    "    random_state=42 # seed\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5, # 임시데이터셋을 1:1 비율로 val과 test로 나누기\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5dee83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 2400\n",
      "300 300\n",
      "300 300\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_val), len(y_val))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "676b14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 객체\n",
    "train_dataset = AudioDataset(X_train, y_train) # X 독립변수, y 종속변수\n",
    "val_dataset   = AudioDataset(X_val,   y_val)\n",
    "test_dataset  = AudioDataset(X_test,  y_test)\n",
    "\n",
    "# 각각의 데이터셋 로드\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e26065d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([32, 16000])\n",
      "Labels: tensor([[0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "inputs, labels = next(train_iter)\n",
    "\n",
    "print(\"Inputs:\", inputs.shape)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f74d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = Cnn14(\n",
    "    sample_rate=16000, # 샘플링 레이트 16k\n",
    "    window_size=512, # 윈도우 사이즈\n",
    "    hop_size=160, # 홉 사이즈\n",
    "    mel_bins=64, # mel 주파수 채널 수\n",
    "    fmin=50, # mel 주파수 최소치\n",
    "    fmax=8000, # mel 주파수 최대치\n",
    "    classes_num=527 # 분류할 클래스 숫자(원본 모델의 클래스 숫자)\n",
    ")\n",
    "\n",
    " # 사전학습된 가중치 로드\n",
    "checkpoint = torch.load(CHECKPOINT, map_location=DEVICE, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model']) # 체크포인트에서 model 가중치만 가져옴\n",
    "\n",
    "# 마지막 완전연결층을 학습할 클래스 개수로 수정 (527 -> CLASS_NUM)\n",
    "model.fc_audioset = torch.nn.Linear(model.fc_audioset.in_features, CLASS_NUM) \n",
    "\n",
    "model = model.to(DEVICE) # gpu로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f3ec65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn14(\n",
      "  (spectrogram_extractor): Spectrogram(\n",
      "    (stft): STFT(\n",
      "      (conv_real): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
      "      (conv_imag): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (logmel_extractor): LogmelFilterBank()\n",
      "  (spec_augmenter): SpecAugmentation(\n",
      "    (time_dropper): DropStripes()\n",
      "    (freq_dropper): DropStripes()\n",
      "  )\n",
      "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_block1): ConvBlock(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block2): ConvBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block3): ConvBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block4): ConvBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block5): ConvBlock(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block6): ConvBlock(\n",
      "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "최종적으로 아래와 같은 모델이 로드됨\n",
    "\n",
    "Cnn14(\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  (비학습 계층)\n",
    "  # 인코더 계층\n",
    "  # 슬라이딩 윈도우 -> 푸리에변환 -> mel -> log-scale 순으로 처리\n",
    "  (spectrogram_extractor): Spectrogram(\n",
    "    (stft): STFT(                                                                         \n",
    "      (conv_real): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
    "      (conv_imag): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
    "    )\n",
    "  )\n",
    "  (logmel_extractor): LogmelFilterBank()\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  (비학습 계층)\n",
    "  # 드롭아웃 계층\n",
    "  # 일부 뉴런의 연결을 해제하여 과적합의 가능성을 낮춤\n",
    "  (spec_augmenter): SpecAugmentation(\n",
    "    (time_dropper): DropStripes()\n",
    "    (freq_dropper): DropStripes()\n",
    "  )\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  (학습 계층)\n",
    "  # 배치정규화 계층\n",
    "  # 각각의 미니배치마다 평균과 분산을 이용하여 통계적인 배치값를 사용하여 지역최솟값을 방지\n",
    "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  (학습 계층)\n",
    "  # 컨볼루션 계층\n",
    "  (conv_block1): ConvBlock(\n",
    "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block2): ConvBlock(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block3): ConvBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block4): ConvBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block5): ConvBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block6): ConvBlock(\n",
    "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  (학습 계층)\n",
    "  # 완전연결 계층\n",
    "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
    "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "\n",
    "  배치정규화 1층 + 컨볼루션 6*4 + 완전연결층 2 총 27개의 레이어\n",
    ")\n",
    "'''\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39da32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # 다중 라벨 이진교차엔트로피 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Adam 최적화함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cbc64005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch[1/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5267, Accuracy: 0.0992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3647, Accuracy: 0.2833\n",
      "\n",
      "Epoch[2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1971, Accuracy: 0.6729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0585, Accuracy: 0.9367\n",
      "\n",
      "Epoch[3/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0947, Accuracy: 0.8662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0272, Accuracy: 0.9733\n",
      "\n",
      "Epoch[4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0639, Accuracy: 0.9179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0126, Accuracy: 0.9933\n",
      "\n",
      "Epoch[5/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0547, Accuracy: 0.9254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0074, Accuracy: 1.0000\n",
      "\n",
      "Epoch[6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0415, Accuracy: 0.9429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0054, Accuracy: 1.0000\n",
      "\n",
      "Epoch[7/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0417, Accuracy: 0.9417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Accuracy: 1.0000\n",
      "\n",
      "Epoch[8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0319, Accuracy: 0.9617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 46.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0021, Accuracy: 1.0000\n",
      "\n",
      "Epoch[9/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0232, Accuracy: 0.9708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0027, Accuracy: 1.0000\n",
      "\n",
      "Epoch[10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0336, Accuracy: 0.9554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0011, Accuracy: 1.0000\n",
      "\n",
      "Epoch[11/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0252, Accuracy: 0.9675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0021, Accuracy: 1.0000\n",
      "\n",
      "Epoch[12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0199, Accuracy: 0.9742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0012, Accuracy: 1.0000\n",
      "\n",
      "Epoch[13/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0261, Accuracy: 0.9663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0008, Accuracy: 1.0000\n",
      "\n",
      "Epoch[14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0163, Accuracy: 0.9783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0005, Accuracy: 1.0000\n",
      "\n",
      "Epoch[15/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0252, Accuracy: 0.9721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0017, Accuracy: 1.0000\n",
      "\n",
      "Epoch[16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0148, Accuracy: 0.9767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 47.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0009, Accuracy: 1.0000\n",
      "\n",
      "Epoch[17/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0183, Accuracy: 0.9788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 48.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0006, Accuracy: 1.0000\n",
      "\n",
      "Epoch[18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0196, Accuracy: 0.9746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 47.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0004, Accuracy: 1.0000\n",
      "\n",
      "Epoch[19/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0152, Accuracy: 0.9788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 47.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0007, Accuracy: 1.0000\n",
      "\n",
      "Epoch[20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0131, Accuracy: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 49.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0007, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch[{epoch+1}/{EPOCHS}]\")\n",
    "\n",
    "    # 학습\n",
    "    train_loss, train_acc = train_epoch(model=model, loader=train_loader, optimizer=optimizer, criterion=criterion, device=DEVICE)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\", end=\"\")\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = validate(model=model, loader=val_loader, criterion=criterion, device=DEVICE)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # 검증 정확도가 가장 좋으면 모델 저장\n",
    "    # if val_acc > best_val_accuracy:\n",
    "    #     best_val_accuracy = val_acc\n",
    "    #     torch.save(model, SAVE_PATH)\n",
    "    \n",
    "torch.save(model, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac2ea83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn14(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 257, kernel_size=(512,), stride=(160,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_block1): ConvBlock(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block2): ConvBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block3): ConvBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block4): ConvBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block5): ConvBlock(\n",
       "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block6): ConvBlock(\n",
       "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 모델 로드\n",
    "model = torch.load(\"./result/best.pt\", weights_only=False)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2aed88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 45.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0013, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, DEVICE)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2.7.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

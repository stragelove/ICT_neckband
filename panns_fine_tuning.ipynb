{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model.cnn14 import Cnn14\n",
    "from model.stft import AudioPreprocessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "557c094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "989ffb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./Dataset/\" # 데이터셋 경로\n",
    "CHECKPOINT = \"./checkpoint/Cnn14_16k_mAP=0.438.pth\" # 모델의 사전학습된 가중치\n",
    "SAVE_BEST_PATH = \"./result/best.pt\" # 학습완료된 모델 저장 위치\n",
    "SAVE_LAST_PATH = \"./result/last.pt\" # 학습완료된 모델 저장 위치\n",
    "CLASS_NAME = [\"danger\", \"fire\", \"gas\", \"non\", \"tsunami\"] # 분류할 클래스\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # torch에 전달할 디바이스 종류\n",
    "\n",
    "# 하이퍼 파라미터\n",
    "CLASS_NUM = len(CLASS_NAME)\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "WINDOW_SIZE = 512\n",
    "HOP_SIZE = 160\n",
    "MEL_BINS = 64\n",
    "FMIN = 50\n",
    "FMAX = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab126c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68f93dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassNameError(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"폴더이름과 클래스이름이 일치 하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98565d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 정의\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels, preprocessor, sample_rate=SAMPLE_RATE, duration=DURATION):\n",
    "        self.filepaths = filepaths # 데이터 경로\n",
    "        self.labels = labels # 라벨\n",
    "        self.sample_rate = sample_rate # 샘플링 레이트\n",
    "        self.num_samples = int(sample_rate * duration) # 오디오 샘플의 길이\n",
    "        self.audio_preprocessor = preprocessor\n",
    "\n",
    "    # 데이터셋의 길이(파일 개수) 반환\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.filepaths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        waveform, sr = torchaudio.load(filepath) # waveform (channel, length)\n",
    "\n",
    "        # 모노(1채널)로 변환\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # 원하는 샘플링 레이트가 아니면 리샘플링\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # 오디오 샘플의 길이조정\n",
    "        if waveform.shape[1] < self.num_samples: # 길이가 부족하면 0(무음)을 채워 길이를 연장\n",
    "            waveform = F.pad(waveform, (0, self.num_samples - waveform.shape[1])) # num_samples와 현재의 길이의 차 만큼 0을 패딩\n",
    "        else:\n",
    "            waveform = waveform[:, :self.num_samples] # 길이가 길면 슬라이싱\n",
    "\n",
    "        # 절댓값 정규화(-1 ~ 1)\n",
    "        waveform = waveform / (waveform.abs().max() + 1e-9)\n",
    "\n",
    "        # input: wavefrom (1, length)\n",
    "        with torch.no_grad():\n",
    "            logmel = self.audio_preprocessor(waveform) # (1, 1, time, mel_bins)\n",
    "            logmel = logmel.squeeze(0) # (1, time, mel_bins)\n",
    "\n",
    "        return logmel, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8403fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습함수\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() # 학습모드\n",
    "    running_loss = 0.0 # 손실\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # 배치 단위로 데이터로드\n",
    "    for waveforms, labels in tqdm(loader, desc=\"학습중\", leave=True):\n",
    "        waveforms = waveforms.to(device) # gpu로 전달\n",
    "        labels = labels.to(device).float() # BCE 손실함수에는 반드시 실수형필요\n",
    "\n",
    "        optimizer.zero_grad() # 경사값 초기화\n",
    "\n",
    "        outputs = model(waveforms)[\"clipwise_output\"] # 모델에 데이터입력\n",
    "\n",
    "        loss = criterion(outputs, labels) # 손실계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 갱신\n",
    "\n",
    "        # 배치 손실을 누적\n",
    "        running_loss += loss.item() * waveforms.size(0)\n",
    "\n",
    "        # 예측 임계값 0.5 이상을 양성 클래스라 판단하여 이진 예측 생성\n",
    "        predicts = (outputs > 0.5).int()\n",
    "        targets = labels.int()\n",
    "\n",
    "        # 모든 클래스가 일치하는 샘플 개수 카운트, 모든 클래스 다 맞아야 정답 처리\n",
    "        total_correct += (predicts == targets).all(dim=1).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total_samples # 평균손실\n",
    "    accuracy = total_correct  / total_samples # 정답 개수 / 전체 예측값 개수\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 검증함수\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval() #평가모드\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # 검증에는 기울기 계산필요없음, 즉 역전파 없음\n",
    "    with torch.no_grad():\n",
    "        for waveforms, labels in tqdm(loader, desc=\"검증중\", leave=True):\n",
    "            waveforms = waveforms.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            outputs = model(waveforms)[\"clipwise_output\"]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * waveforms.size(0)\n",
    "\n",
    "            predicts = (outputs > 0.5).int()\n",
    "            targets = labels.int()\n",
    "\n",
    "            total_correct += (predicts == targets).all(dim=1).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = total_correct  / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d1c7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 라벨\n",
    "filepaths, labels = [], []\n",
    "\n",
    "# 데이터셋과 하위폴더에서 확장자가 \"wav\"인 파일의 경로와 라벨(폴더이름) 저장\n",
    "for root, _, files in os.walk(DATASET):\n",
    "    folder_name = os.path.basename(root)\n",
    "\n",
    "    # 폴더명이 클래스 리스트에 없는 경우 에러\n",
    "    if folder_name not in CLASS_NAME and folder_name != \"\":\n",
    "        raise ClassNameError\n",
    "    \n",
    "    for file in files:\n",
    "        if not file.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "        \n",
    "        filepaths.append(os.path.join(root, file))\n",
    "        labels.append(folder_name)\n",
    "\n",
    "# 문자열 라벨 → 정수인코딩 → 원핫인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(labels).reshape(-1, 1)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_labels = onehot_encoder.fit_transform(integer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ff12fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "91abf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 8:1:1의 비율을 가진 학습, 검증, 테스트로 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    filepaths, # X\n",
    "    encoded_labels, # y\n",
    "    test_size=0.2, # train과 임시데이터셋 비율 8:2\n",
    "    stratify=labels, # 기준값을 기준으로 동일한 클래스의 비율로 나누기\n",
    "    random_state=42 # seed\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5, # 임시데이터셋을 1:1 비율로 val과 test로 나누기\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5dee83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 2400\n",
      "300 300\n",
      "300 300\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_val), len(y_val))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "676b14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_preprocessor = AudioPreprocessor(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    hop_size=HOP_SIZE,\n",
    "    mel_bins=MEL_BINS,\n",
    "    fmin=FMIN,\n",
    "    fmax=FMAX\n",
    ")\n",
    "\n",
    "# Dataset 객체\n",
    "train_dataset = AudioDataset(X_train, y_train, audio_preprocessor) # X 독립변수, y 종속변수\n",
    "val_dataset   = AudioDataset(X_val,   y_val, audio_preprocessor)\n",
    "test_dataset  = AudioDataset(X_test,  y_test, audio_preprocessor)\n",
    "\n",
    "# 각각의 데이터셋 로드\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e26065d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "logmel torch.Size([1, 1, 101, 64])\n",
      "Inputs: torch.Size([32, 1, 101, 64])\n",
      "Labels: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "inputs, labels = next(train_iter)\n",
    "\n",
    "print(\"Inputs:\", inputs.shape)\n",
    "print(\"Labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f74d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = Cnn14(\n",
    "    # sample_rate=16000, # 샘플링 레이트 16k\n",
    "    # window_size=512, # 윈도우 사이즈\n",
    "    # hop_size=160, # 홉 사이즈\n",
    "    # mel_bins=64, # mel 주파수 채널 수\n",
    "    # fmin=50, # mel 주파수 최소치\n",
    "    # fmax=8000, # mel 주파수 최대치\n",
    "    classes_num=527 # 분류할 클래스 숫자(원본 모델의 클래스 숫자)\n",
    ")\n",
    "\n",
    " # 사전학습된 가중치 로드\n",
    "checkpoint = torch.load(CHECKPOINT, map_location=DEVICE, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model'], strict=False) # 체크포인트에서 model 가중치만 가져옴\n",
    "\n",
    "# 마지막 완전연결층을 학습할 클래스 개수로 수정 (527 -> CLASS_NUM)\n",
    "model.fc_audioset = torch.nn.Linear(model.fc_audioset.in_features, CLASS_NUM) \n",
    "\n",
    "model = model.to(DEVICE) # gpu로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f3ec65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn14(\n",
      "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_block1): ConvBlock(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block2): ConvBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block3): ConvBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block4): ConvBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block5): ConvBlock(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block6): ConvBlock(\n",
      "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "최종적으로 아래와 같은 모델이 로드됨\n",
    "\n",
    "Cnn14(\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  # 배치정규화 계층\n",
    "  # 각각의 미니배치마다 평균과 분산을 이용하여 통계적인 배치값를 사용하여 지역최솟값을 방지\n",
    "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  # 컨볼루션 계층\n",
    "  (conv_block1): ConvBlock(\n",
    "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block2): ConvBlock(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block3): ConvBlock(\n",
    "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block4): ConvBlock(\n",
    "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block5): ConvBlock(\n",
    "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (conv_block6): ConvBlock(\n",
    "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "  # 완전연결 계층\n",
    "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
    "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
    "  ---------------------------------------------------------------------------------------------\n",
    "\n",
    "  배치정규화 1층 + 컨볼루션 6*4 + 완전연결층 2 총 27개의 레이어\n",
    ")\n",
    "'''\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "39da32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # 다중 라벨 이진교차엔트로피 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Adam 최적화함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cbc64005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch[1/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:16<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3505, Accuracy: 0.4579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:01<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0788, Accuracy: 0.9633\n",
      "\n",
      "Epoch[2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0495, Accuracy: 0.9454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0122, Accuracy: 0.9933\n",
      "\n",
      "Epoch[3/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0211, Accuracy: 0.9775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0062, Accuracy: 0.9933\n",
      "\n",
      "Epoch[4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:06<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0125, Accuracy: 0.9858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026, Accuracy: 1.0000\n",
      "\n",
      "Epoch[5/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:06<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089, Accuracy: 0.9892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0018, Accuracy: 1.0000\n",
      "\n",
      "Epoch[6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0060, Accuracy: 0.9946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0014, Accuracy: 1.0000\n",
      "\n",
      "Epoch[7/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0045, Accuracy: 0.9954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0005, Accuracy: 1.0000\n",
      "\n",
      "Epoch[8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0041, Accuracy: 0.9942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0006, Accuracy: 1.0000\n",
      "\n",
      "Epoch[9/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022, Accuracy: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0003, Accuracy: 1.0000\n",
      "\n",
      "Epoch[10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0018, Accuracy: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0005, Accuracy: 1.0000\n",
      "\n",
      "Epoch[11/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:06<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0021, Accuracy: 0.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0004, Accuracy: 1.0000\n",
      "\n",
      "Epoch[12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019, Accuracy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0002, Accuracy: 1.0000\n",
      "\n",
      "Epoch[13/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017, Accuracy: 0.9979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0002, Accuracy: 1.0000\n",
      "\n",
      "Epoch[14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019, Accuracy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0001, Accuracy: 1.0000\n",
      "\n",
      "Epoch[15/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0007, Accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0003, Accuracy: 1.0000\n",
      "\n",
      "Epoch[16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010, Accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0001, Accuracy: 1.0000\n",
      "\n",
      "Epoch[17/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0011, Accuracy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0001, Accuracy: 1.0000\n",
      "\n",
      "Epoch[18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005, Accuracy: 0.9996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0002, Accuracy: 1.0000\n",
      "\n",
      "Epoch[19/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0004, Accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0002, Accuracy: 1.0000\n",
      "\n",
      "Epoch[20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습중: 100%|██████████| 75/75 [00:05<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005, Accuracy: 0.9996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:00<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0001, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch[{epoch+1}/{EPOCHS}]\")\n",
    "\n",
    "    # 학습\n",
    "    train_loss, train_acc = train_epoch(model=model, loader=train_loader, optimizer=optimizer, criterion=criterion, device=DEVICE)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\", end=\"\")\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_acc = validate(model=model, loader=val_loader, criterion=criterion, device=DEVICE)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # 검증 정확도가 가장 좋으면 모델 저장\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(model, SAVE_BEST_PATH)\n",
    "    \n",
    "torch.save(model, SAVE_LAST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac2ea83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn14(\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_block1): ConvBlock(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block2): ConvBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block3): ConvBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block4): ConvBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block5): ConvBlock(\n",
       "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_block6): ConvBlock(\n",
       "    (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc_audioset): Linear(in_features=2048, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 모델 로드\n",
    "model = torch.load(\"./result/best.pt\", weights_only=False)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2aed88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증중: 100%|██████████| 10/10 [00:01<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0080, Accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, DEVICE)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2.6.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
